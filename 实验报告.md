# 实验报告

## 实验介绍
根据实验要求：<br>
我选择的模型有三个：**mlp**，**vgg19**，**resnet34**。其中mlp是自己实现的，vgg19和resnet34过于经典，于是用的torchvision的官方实现，详见[model.py](models.py)<br>
我选择的优化器有两个：**sgd**和**adamw**<br>
我选择的优化率有三个：**5e-3**，**5e-4**，**5e-5**<br>
所以我一共做了 **3 * 2 * 3 = 18** 个实验，详见[mlp](mlp), [vgg19](vgg19), [resnet34](resnet34),这些文件夹里记录了train log，checkpoint由于太大，就没上传了。<br>
>注：<br>
> 所有实验均单卡训练<br>
> 为了方便收敛，lr 策略均采用 cosine 衰减<br>
> 由于我的 lr 设置的跨度较大，有的训练跑飞了，但这也非常能反映问题，故没有调参使其正常收敛<br>
> 所有的实验的 batch size 均设置为 128<br>
> 所有实验的训练 epochs 均设置为 100

## 消融实验
消融实验我分三个部分：
1. **不同学习率（模型，优化器相同）**，所有实验对比图在[diff_lr](plot/diff_lr)目录下，绘图脚本在[diff_lr/plot.py](plot/diff_lr/plot.py)
2. **不同优化器（模型，学习率相同）**，所有实验对比图在[diff_opt](plot/diff_opt)目录下，绘图脚本在[diff_opt/plot.py](plot/diff_opt/plot.py)
3. **不同模型（优化器，学习率相同）**，所有实验对比图在[diff_mdl](plot/diff_mdl)目录下，绘图脚本在[diff_mdl/plot.py](plot/diff_mdl/plot.py)
> 注：<br>
> 由于实验结果数据太多，下面分析只挑选有代表性的做汇报<br>
> 完整实验请到对应目录查看<br>

### 不同学习率（模型，优化器相同）

### 不同优化器（模型，学习率相同）

### 不同模型（优化器，学习率相同）